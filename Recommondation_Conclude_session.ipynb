{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5a5b653",
   "metadata": {},
   "source": [
    "# Conclude Session of Recommondation System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfc160d",
   "metadata": {},
   "source": [
    "Progress so far:\n",
    "1. Data Cleaning and Modification\n",
    "2. Clustering on whole data\n",
    "3. Data Segmentation based on consistency\n",
    "4. Deep learning mode on consistent groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b24d219",
   "metadata": {},
   "source": [
    "In this page, I'm going to construct a re-cap of my previous work with a clean and clear version. Then made some modification on clustering and data segmentation for the sake of next step's preparation.\n",
    "\n",
    "The idea includes:\n",
    "1. Conclude M18 and 19\n",
    "2. Modify the way of data segmentation (v1-v3)\n",
    "3. Other algorithms of clustering\n",
    "4. Confirm how the recommendation system perform\n",
    "5. Make sure the system is good for new data inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7825d092",
   "metadata": {},
   "source": [
    "## Data Loading and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4006337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(r'C:\\Frank\\UoT 2024-2025\\MIE8888 Project\\M18\\RUIWU') \n",
    "from helper_functions import * # Import Ruiwu's helper functions for data cleaning, slicing and aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1b6e107",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_9708\\1752406196.py:3: DtypeWarning: Columns (1,4,10,16,52,85,86,91) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(full_dataset, encoding=\"Windows-1252\")\n",
      "c:\\Frank\\UoT 2024-2025\\MIE8888 Project\\SmilePass-2\\helper_functions.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  temp_dt = pd.to_datetime(df[col], errors='raise')\n",
      "c:\\Frank\\UoT 2024-2025\\MIE8888 Project\\SmilePass-2\\helper_functions.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  temp_dt = pd.to_datetime(df[col], errors='raise')\n",
      "c:\\Frank\\UoT 2024-2025\\MIE8888 Project\\SmilePass-2\\helper_functions.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  temp_dt = pd.to_datetime(df[col], errors='raise')\n",
      "c:\\Frank\\UoT 2024-2025\\MIE8888 Project\\SmilePass-2\\helper_functions.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  temp_dt = pd.to_datetime(df[col], errors='raise')\n",
      "c:\\Frank\\UoT 2024-2025\\MIE8888 Project\\SmilePass-2\\helper_functions.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  temp_dt = pd.to_datetime(df[col], errors='raise')\n",
      "c:\\Frank\\UoT 2024-2025\\MIE8888 Project\\SmilePass-2\\helper_functions.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  temp_dt = pd.to_datetime(df[col], errors='raise')\n"
     ]
    }
   ],
   "source": [
    "# Get current ful data\n",
    "full_dataset = r\"C:\\Frank\\UoT 2024-2025\\MIE8888 Project\\full_dataset_2.11.csv\"\n",
    "df = pd.read_csv(full_dataset, encoding=\"Windows-1252\")\n",
    "\n",
    "# Define trash columns\n",
    "trash_columns = ['id_x_x','sikka_sub_task_operation_x_x','office_x_x','guarantor_x','patient','description','visible_to_patient','primary_insurance_estimate','secondary_insurance_estimate','plan_sr_no','insurance_payment','approved','from_pms_x_x','id_y_x','from_pms_y_x','sikka_sub_task_y_x','sikka_sub_task_operation_y_x','uuid','guarantor_y','office_y_x','fullname','first_name','last_name','address','phone','zip_code','practice','primary_insurance_company_id','profile_picture','date_joined','zip_code_flag','address_comp','final_zip_code','id_x_y','from_pms_x_y','office_x_y','treatment','id_y_y','from_pms_y_y','sikka_sub_task_y_y','sikka_sub_task_operation_y_y','office_y_y','procedure_code_x','procedure_code_description','patient_friendly_description','treatment_id','price','fetched_zip_code_flag','zip_code_verified','fetched_zip_code', 'entry_date', 'tooth_from']\n",
    "\n",
    "# Data Engineering\n",
    "df = drop_high_nan_columns(df) \n",
    "df = df.drop(columns = trash_columns) # Drop trash cols\n",
    "df = merge_columns_with_priority(df,'health_category','procedure_code_category','treatment_category') # merge to get treatment_category with pattern from two category groups\n",
    "df = df.dropna() # Drop the remaining NA\n",
    "df, df_dict = object_processing(df) # Project columns dtype = object; For columns containing datetime, convert it to pd.datetime; For other object columns, encode them\n",
    "df = days_cal(df,'procedure_date','birth_date', 'procedure_age') # age group preparation (modify to int)\n",
    "df = days_cal(df,'last_visit','first_visit','visit_period')\n",
    "\n",
    "# Perform one-hot encoding on the \"procedure_code_y\" and \"treatment_category\"\n",
    "df = one_hot_encode_procedure_and_treatment(df)\n",
    "# df.to_csv(r'C:\\Frank\\UoT 2024-2025\\MIE8888 Project\\M18\\output.csv', index=False)\n",
    "df_next = df.copy() # for next step use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de427949",
   "metadata": {},
   "source": [
    "- Create a complete dataset to reflect each patient_id's treatment pattern (aassuming all meta columns stand the same for each unique patient id)\n",
    "- Applied Truncated SVD which is the best for sparse binary data of large sparse matrices.\n",
    "\n",
    "Note: `final_df` is generated from whole dataset; `df_svd` is based on it. Replace it with any new version of dataset if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587ef62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Define Constant columns\n",
    "meta_cols = ['provider_x', 'amount', 'treatment_plan_status', 'patient_id', 'city','state_y', 'sikka_provider_id', 'LATITUDE', 'LONGITUDE', 'procedure_age', 'visit_period']\n",
    "\n",
    "# Select relevant columns\n",
    "base_cols = ['patient_id', 'procedure_age']\n",
    "procedure_cols = [col for col in df_next.columns if col.startswith('procedure_code_y_') or col.startswith('treatment_category_')]\n",
    "df_subset = df_next[base_cols + procedure_cols].copy()\n",
    "df_subset['procedure_age'] = df_subset['procedure_age'].astype(int) # procedure_age to int\n",
    "\n",
    "# Melt one-hot to long format\n",
    "df_long = df_subset.melt(\n",
    "    id_vars=['patient_id', 'procedure_age'],\n",
    "    value_vars=procedure_cols,\n",
    "    var_name='procedure_code',\n",
    "    value_name='occurred'\n",
    ")\n",
    "\n",
    "# Keep only rows where procedure occurred\n",
    "df_long = df_long[df_long['occurred'] == 1]\n",
    "\n",
    "# Create combined feature name\n",
    "df_long['feature'] = df_long['procedure_code'] + '_age' + df_long['procedure_age'].astype(str)\n",
    "\n",
    "# Pivot to wide format\n",
    "final_df = df_long.groupby(['patient_id', 'feature']).size().unstack(fill_value=0)\n",
    "final_df = final_df.reset_index()\n",
    "\n",
    "# Get metadata (take first row per patient) # may need further fixing if the information for such patient changed over times\n",
    "patient_meta = df_next[meta_cols].groupby('patient_id').first().reset_index()\n",
    "final_df = pd.merge(patient_meta, final_df, on='patient_id', how='left')\n",
    "\n",
    "# columns to exclude from SVD\n",
    "non_binary_cols = ['provider_x', 'amount', 'treatment_plan_status', 'patient_id', 'city','state_y', 'sikka_provider_id', 'LATITUDE', 'LONGITUDE','procedure_age', 'visit_period']\n",
    "meta_df = final_df[non_binary_cols].copy()\n",
    "binary_df = final_df.drop(columns=non_binary_cols)\n",
    "\n",
    "# Apply TruncatedSVD on binary columns\n",
    "X_sparse = csr_matrix(binary_df.values)\n",
    "svd = TruncatedSVD(n_components=100, random_state=823)\n",
    "X_svd = svd.fit_transform(X_sparse)\n",
    "svd_features = pd.DataFrame(X_svd, columns=[f\"SVD_{i+1}\" for i in range(X_svd.shape[1])])\n",
    "df_svd = pd.concat([meta_df.reset_index(drop=True), svd_features], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1654a3",
   "metadata": {},
   "source": [
    "- Dataframe for 17 age groups, start from 5-10, up to 85-90\n",
    "- Dataframe for each age groups\n",
    "\n",
    "Note: Change `df` to any version of `dataset` if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97580478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 5 year window\n",
    "def age_to_group(age):\n",
    "    try:\n",
    "        age = int(age)\n",
    "        if age < 0:\n",
    "            return \"invalid\"\n",
    "        lower = (age // 5) * 5\n",
    "        upper = lower + 5\n",
    "        if lower > upper:\n",
    "            return \"invalid\"\n",
    "        return f\"{lower}-{upper}\"\n",
    "    except:\n",
    "        return \"invalid\"\n",
    "\n",
    "df['age_group'] = df['procedure_age'].apply(age_to_group)\n",
    "output_dir = r\"C:\\Frank\\UoT 2024-2025\\MIE8888 Project\\M18\\Split dataframe 5 year\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "# Split and save each group\n",
    "for group_name, group_df in df.groupby('age_group'):\n",
    "    filename = f\"{output_dir}/age_group_{group_name}.csv\"\n",
    "    group_df.to_csv(filename, index=False)\n",
    "    print(f\"Saved: {filename}\")\n",
    "\n",
    "\n",
    "# 1 year window\n",
    "def age_to_group(age):\n",
    "    try:\n",
    "        age = int(age)\n",
    "        if age < 0:\n",
    "            return \"invalid\"\n",
    "        return f\"{age}-{age + 1}\"\n",
    "    except:\n",
    "        return \"invalid\"\n",
    "\n",
    "df['age_group'] = df['procedure_age'].apply(age_to_group)\n",
    "output_dir = r\"C:\\Frank\\UoT 2024-2025\\MIE8888 Project\\M18\\Split dataframe yearly\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "# Split and save each group\n",
    "for group_name, group_df in df.groupby('age_group'):\n",
    "    if group_name == \"invalid\":\n",
    "        continue  # Skip invalid entries\n",
    "    filename = os.path.join(output_dir, f\"age_group_{group_name}.csv\")\n",
    "    group_df.to_csv(filename, index=False)\n",
    "    print(f\"Saved: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d855eeb2",
   "metadata": {},
   "source": [
    "End up with 2 key datasets:   \n",
    "Dataset 1: Separated datasets which are split by age groups. (5-year or yearly)  \n",
    "Dataset 2: One complete dataset to contain all treatment history of each patient_id throughout all of their procedure time. (SVD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59bd4f7",
   "metadata": {},
   "source": [
    "## Data Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfd0305",
   "metadata": {},
   "source": [
    "### Divide patient-level treatment dataset into three groups (V1, V2, V3) based on the continuity and duration of their visit history\n",
    "Definitions:\n",
    "- First Visit Date: Start of treatment history\n",
    "- Last Visit Date: End of treatment history\n",
    "- Procedure Data: The date which procedure occurred\n",
    "- Max Gap: Largest time gap between consecutive visits\n",
    "- Duration: Total time span = Last Visit Date - First Visit Date\n",
    "\n",
    "V1 (Very Consistent): Max gap between visits is less than 2 years (Doesn’t matter how long the total history is, as long as it's consistent)  \n",
    "V2 (Inconsistent but Long History): Max gap is 2 years or more; Total duration is 7 years or more  \n",
    "V3 (Inconsistent and Short History): Everything else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "356e3c3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'procedure_date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9708\\1610144994.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'V3'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# Apply the classification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mpatient_versions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_next\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'patient_id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassify_patient\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mpatient_versions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'patient_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'version'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# Merge version info back to full dataset (Treatment Based)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\frank\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, func, include_groups, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1833\u001b[0m                         \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1834\u001b[0m                         \u001b[0mcategory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDeprecationWarning\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1835\u001b[0m                         \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1836\u001b[0m                     \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1837\u001b[1;33m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1838\u001b[0m                 \u001b[1;31m# gh-20949\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1839\u001b[0m                 \u001b[1;31m# try again, with .apply acting as a filtering\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1840\u001b[0m                 \u001b[1;31m# operation, by excluding the grouping column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\frank\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[0;32m   1881\u001b[0m         \u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1882\u001b[0m         \u001b[0mSeries\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1883\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mapplying\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1884\u001b[0m         \"\"\"\n\u001b[1;32m-> 1885\u001b[1;33m         \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_grouper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_groupwise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1886\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnot_indexed_same\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1887\u001b[0m             \u001b[0mnot_indexed_same\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmutated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1888\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\frank\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, f, data, axis)\u001b[0m\n\u001b[0;32m    915\u001b[0m             \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"name\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m             \u001b[1;31m# group might be modified\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    918\u001b[0m             \u001b[0mgroup_axes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 919\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    920\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmutated\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_is_indexed_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    921\u001b[0m                 \u001b[0mmutated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m             \u001b[0mresult_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9708\\1610144994.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(group)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclassify_patient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprocedure_dates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'procedure_date'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'procedure_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# Visit span in years\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mspan_years\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'last_visit'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'first_visit'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdays\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m365.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\frank\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   7185\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7186\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7187\u001b[0m             \u001b[1;31m# len(by) == 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7189\u001b[1;33m             \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7191\u001b[0m             \u001b[1;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7192\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\frank\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1908\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1910\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1911\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1913\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1914\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'procedure_date'"
     ]
    }
   ],
   "source": [
    "def classify_patient(group):\n",
    "    procedure_dates = group.sort_values('procedure_date')['procedure_date']\n",
    "    \n",
    "    # Visit span in years\n",
    "    span_years = (group['last_visit'].iloc[0] - group['first_visit'].iloc[0]).days / 365.0\n",
    "\n",
    "    # Maximum time gap between consecutive visits\n",
    "    gaps = procedure_dates.diff().dropna().dt.days / 365.0\n",
    "    max_gap = gaps.max() if not gaps.empty else 0\n",
    "\n",
    "    # Classification\n",
    "    if span_years >= 1 and max_gap <= 2:\n",
    "        return 'V1'\n",
    "    elif span_years >= 7:\n",
    "        return 'V2'\n",
    "    else:\n",
    "        return 'V3'\n",
    "\n",
    "# Apply the classification\n",
    "patient_versions = df_next.groupby('patient_id').apply(classify_patient).reset_index()\n",
    "patient_versions.columns = ['patient_id', 'version']\n",
    "\n",
    "# Merge version info back to full dataset (Treatment Based)\n",
    "df_next = df_next.merge(patient_versions, on='patient_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6284629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v1 = df_next[df_next['version'] == 'V1']\n",
    "df_v2 = df_next[df_next['version'] == 'V2']\n",
    "df_v3 = df_next[df_next['version'] == 'V3']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
